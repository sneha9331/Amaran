# -------------------- Importing Required Libraries --------------------
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# -------------------- Load Dataset --------------------

df = pd.read_csv(r"/content/emails.csv")   # <-- change path if needed

print("First 5 rows:\n", df.head())
print("\nDataset Information:")
print(df.info())
print("\nMissing values:\n", df.isnull().sum())

# -------------------- Define Features (X) and Target (Y) --------------------
# Assuming dataset columns: [Email_No., word_freq_1, ..., word_freq_n, spam]

X = df.iloc[:, 1:-1].values    # input features
Y = df.iloc[:, -1].values      # target label (1 = spam, 0 = not spam)

print("Shape of X:", X.shape)
print("Shape of Y:", Y.shape)

# -------------------- Split Data into Training and Testing Sets --------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, Y, test_size=0.25, random_state=42
)

print("Training Data Shape:", X_train.shape)
print("Testing Data Shape:", X_test.shape)

# -------------------- Feature Scaling --------------------
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Feature scaling complete.")

# =====================================================================
# ðŸ§  Support Vector Machine (SVM) Model with Hyperparameter Tuning
# =====================================================================

svc = SVC()
svc_params = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto']
}

svc_grid = GridSearchCV(svc, svc_params, cv=5, scoring='accuracy')
svc_grid.fit(X_train, y_train)

svc_best = svc_grid.best_estimator_
svc_pred = svc_best.predict(X_test)

print("\n--- SVM Results ---")
print("Best Parameters:", svc_grid.best_params_)
print("Accuracy:", accuracy_score(y_test, svc_pred))
print("Classification Report:\n", classification_report(y_test, svc_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, svc_pred))

# =====================================================================
# ðŸ§  K-Nearest Neighbors (KNN) Model with Hyperparameter Tuning
# =====================================================================

knn = KNeighborsClassifier()
knn_params = {
    'n_neighbors': [3, 5, 7, 9],
    'weights': ['uniform', 'distance'],
    'p': [1, 2]  # 1 = Manhattan, 2 = Euclidean
}

knn_grid = GridSearchCV(knn, knn_params, cv=5, scoring='accuracy')
knn_grid.fit(X_train, y_train)

knn_best = knn_grid.best_estimator_
knn_pred = knn_best.predict(X_test)

print("\n--- KNN Results ---")
print("Best Parameters:", knn_grid.best_params_)
print("Accuracy:", accuracy_score(y_test, knn_pred))
print("Classification Report:\n", classification_report(y_test, knn_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, knn_pred))

# =====================================================================
# ðŸ“Š Comparison Summary
# =====================================================================

print("\n================== MODEL COMPARISON ==================")
print(f"SVM Accuracy: {accuracy_score(y_test, svc_pred):.4f}")
print(f"KNN Accuracy: {accuracy_score(y_test, knn_pred):.4f}")

if accuracy_score(y_test, svc_pred) > accuracy_score(y_test, knn_pred):
    print("\nâœ… SVM performs better than KNN for this dataset.")
else:
    print("\nâœ… KNN performs better than SVM for this dataset.")
